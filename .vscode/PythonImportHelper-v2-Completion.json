[
    {
        "label": "cv2",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "cv2",
        "description": "cv2",
        "detail": "cv2",
        "documentation": {}
    },
    {
        "label": "numpy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "numpy",
        "description": "numpy",
        "detail": "numpy",
        "documentation": {}
    },
    {
        "label": "Image",
        "importPath": "PIL",
        "description": "PIL",
        "isExtraImport": true,
        "detail": "PIL",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "alive_bar",
        "importPath": "alive_progress",
        "description": "alive_progress",
        "isExtraImport": true,
        "detail": "alive_progress",
        "documentation": {}
    },
    {
        "label": "time",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "time",
        "description": "time",
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "sleep",
        "importPath": "time",
        "description": "time",
        "isExtraImport": true,
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "sleep",
        "importPath": "time",
        "description": "time",
        "isExtraImport": true,
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "sleep",
        "importPath": "time",
        "description": "time",
        "isExtraImport": true,
        "detail": "time",
        "documentation": {}
    },
    {
        "label": "ChromeDriverManager",
        "importPath": "webdriver_manager.chrome",
        "description": "webdriver_manager.chrome",
        "isExtraImport": true,
        "detail": "webdriver_manager.chrome",
        "documentation": {}
    },
    {
        "label": "ChromeDriverManager",
        "importPath": "webdriver_manager.chrome",
        "description": "webdriver_manager.chrome",
        "isExtraImport": true,
        "detail": "webdriver_manager.chrome",
        "documentation": {}
    },
    {
        "label": "ChromeDriverManager",
        "importPath": "webdriver_manager.chrome",
        "description": "webdriver_manager.chrome",
        "isExtraImport": true,
        "detail": "webdriver_manager.chrome",
        "documentation": {}
    },
    {
        "label": "Options",
        "importPath": "selenium.webdriver.chrome.options",
        "description": "selenium.webdriver.chrome.options",
        "isExtraImport": true,
        "detail": "selenium.webdriver.chrome.options",
        "documentation": {}
    },
    {
        "label": "Options",
        "importPath": "selenium.webdriver.chrome.options",
        "description": "selenium.webdriver.chrome.options",
        "isExtraImport": true,
        "detail": "selenium.webdriver.chrome.options",
        "documentation": {}
    },
    {
        "label": "Options",
        "importPath": "selenium.webdriver.chrome.options",
        "description": "selenium.webdriver.chrome.options",
        "isExtraImport": true,
        "detail": "selenium.webdriver.chrome.options",
        "documentation": {}
    },
    {
        "label": "Service",
        "importPath": "selenium.webdriver.chrome.service",
        "description": "selenium.webdriver.chrome.service",
        "isExtraImport": true,
        "detail": "selenium.webdriver.chrome.service",
        "documentation": {}
    },
    {
        "label": "Service",
        "importPath": "selenium.webdriver.chrome.service",
        "description": "selenium.webdriver.chrome.service",
        "isExtraImport": true,
        "detail": "selenium.webdriver.chrome.service",
        "documentation": {}
    },
    {
        "label": "Service",
        "importPath": "selenium.webdriver.chrome.service",
        "description": "selenium.webdriver.chrome.service",
        "isExtraImport": true,
        "detail": "selenium.webdriver.chrome.service",
        "documentation": {}
    },
    {
        "label": "By",
        "importPath": "selenium.webdriver.common.by",
        "description": "selenium.webdriver.common.by",
        "isExtraImport": true,
        "detail": "selenium.webdriver.common.by",
        "documentation": {}
    },
    {
        "label": "By",
        "importPath": "selenium.webdriver.common.by",
        "description": "selenium.webdriver.common.by",
        "isExtraImport": true,
        "detail": "selenium.webdriver.common.by",
        "documentation": {}
    },
    {
        "label": "By",
        "importPath": "selenium.webdriver.common.by",
        "description": "selenium.webdriver.common.by",
        "isExtraImport": true,
        "detail": "selenium.webdriver.common.by",
        "documentation": {}
    },
    {
        "label": "webdriver",
        "importPath": "selenium",
        "description": "selenium",
        "isExtraImport": true,
        "detail": "selenium",
        "documentation": {}
    },
    {
        "label": "webdriver",
        "importPath": "selenium",
        "description": "selenium",
        "isExtraImport": true,
        "detail": "selenium",
        "documentation": {}
    },
    {
        "label": "webdriver",
        "importPath": "selenium",
        "description": "selenium",
        "isExtraImport": true,
        "detail": "selenium",
        "documentation": {}
    },
    {
        "label": "playsound",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "playsound",
        "description": "playsound",
        "detail": "playsound",
        "documentation": {}
    },
    {
        "label": "warnings",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "warnings",
        "description": "warnings",
        "detail": "warnings",
        "documentation": {}
    },
    {
        "label": "pyttsx3",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pyttsx3",
        "description": "pyttsx3",
        "detail": "pyttsx3",
        "documentation": {}
    },
    {
        "label": "Listen",
        "importPath": "Functions.Listen",
        "description": "Functions.Listen",
        "isExtraImport": true,
        "detail": "Functions.Listen",
        "documentation": {}
    },
    {
        "label": "Speak",
        "importPath": "Functions.Speak",
        "description": "Functions.Speak",
        "isExtraImport": true,
        "detail": "Functions.Speak",
        "documentation": {}
    },
    {
        "label": "recognizer",
        "kind": 5,
        "importPath": "Authentication.Recognition",
        "description": "Authentication.Recognition",
        "peekOfCode": "recognizer = cv2.face.LBPHFaceRecognizer_create() # Local Binary Patterns Histograms\nrecognizer.read('Database//Trained_Modal//Traineddata.yml')   #load trained model\ncascadePath = \"Database//Haarcascades//haarcascade_frontalface_default.xml\"\nfaceCascade = cv2.CascadeClassifier(cascadePath) #initializing haar cascade for object detection approach\nfont = cv2.FONT_HERSHEY_SIMPLEX #denotes the font type\nids = 2 #number of persons you want to Recognize\nnames = ['Aanya',\"Arnav\"]  #names, leave first empty bcz counter starts from 0\ncam = cv2.VideoCapture(0, cv2.CAP_DSHOW) #cv2.CAP_DSHOW to remove warning\ncam.set(3, 640) # set video FrameWidht\ncam.set(4, 480) # set video FrameHeight",
        "detail": "Authentication.Recognition",
        "documentation": {}
    },
    {
        "label": "cascadePath",
        "kind": 5,
        "importPath": "Authentication.Recognition",
        "description": "Authentication.Recognition",
        "peekOfCode": "cascadePath = \"Database//Haarcascades//haarcascade_frontalface_default.xml\"\nfaceCascade = cv2.CascadeClassifier(cascadePath) #initializing haar cascade for object detection approach\nfont = cv2.FONT_HERSHEY_SIMPLEX #denotes the font type\nids = 2 #number of persons you want to Recognize\nnames = ['Aanya',\"Arnav\"]  #names, leave first empty bcz counter starts from 0\ncam = cv2.VideoCapture(0, cv2.CAP_DSHOW) #cv2.CAP_DSHOW to remove warning\ncam.set(3, 640) # set video FrameWidht\ncam.set(4, 480) # set video FrameHeight\n# Define min window size to be recognized as a face\nminW = 0.1*cam.get(3)",
        "detail": "Authentication.Recognition",
        "documentation": {}
    },
    {
        "label": "faceCascade",
        "kind": 5,
        "importPath": "Authentication.Recognition",
        "description": "Authentication.Recognition",
        "peekOfCode": "faceCascade = cv2.CascadeClassifier(cascadePath) #initializing haar cascade for object detection approach\nfont = cv2.FONT_HERSHEY_SIMPLEX #denotes the font type\nids = 2 #number of persons you want to Recognize\nnames = ['Aanya',\"Arnav\"]  #names, leave first empty bcz counter starts from 0\ncam = cv2.VideoCapture(0, cv2.CAP_DSHOW) #cv2.CAP_DSHOW to remove warning\ncam.set(3, 640) # set video FrameWidht\ncam.set(4, 480) # set video FrameHeight\n# Define min window size to be recognized as a face\nminW = 0.1*cam.get(3)\nminH = 0.1*cam.get(4)",
        "detail": "Authentication.Recognition",
        "documentation": {}
    },
    {
        "label": "font",
        "kind": 5,
        "importPath": "Authentication.Recognition",
        "description": "Authentication.Recognition",
        "peekOfCode": "font = cv2.FONT_HERSHEY_SIMPLEX #denotes the font type\nids = 2 #number of persons you want to Recognize\nnames = ['Aanya',\"Arnav\"]  #names, leave first empty bcz counter starts from 0\ncam = cv2.VideoCapture(0, cv2.CAP_DSHOW) #cv2.CAP_DSHOW to remove warning\ncam.set(3, 640) # set video FrameWidht\ncam.set(4, 480) # set video FrameHeight\n# Define min window size to be recognized as a face\nminW = 0.1*cam.get(3)\nminH = 0.1*cam.get(4)\n# flag = True",
        "detail": "Authentication.Recognition",
        "documentation": {}
    },
    {
        "label": "ids",
        "kind": 5,
        "importPath": "Authentication.Recognition",
        "description": "Authentication.Recognition",
        "peekOfCode": "ids = 2 #number of persons you want to Recognize\nnames = ['Aanya',\"Arnav\"]  #names, leave first empty bcz counter starts from 0\ncam = cv2.VideoCapture(0, cv2.CAP_DSHOW) #cv2.CAP_DSHOW to remove warning\ncam.set(3, 640) # set video FrameWidht\ncam.set(4, 480) # set video FrameHeight\n# Define min window size to be recognized as a face\nminW = 0.1*cam.get(3)\nminH = 0.1*cam.get(4)\n# flag = True\nwhile True:",
        "detail": "Authentication.Recognition",
        "documentation": {}
    },
    {
        "label": "names",
        "kind": 5,
        "importPath": "Authentication.Recognition",
        "description": "Authentication.Recognition",
        "peekOfCode": "names = ['Aanya',\"Arnav\"]  #names, leave first empty bcz counter starts from 0\ncam = cv2.VideoCapture(0, cv2.CAP_DSHOW) #cv2.CAP_DSHOW to remove warning\ncam.set(3, 640) # set video FrameWidht\ncam.set(4, 480) # set video FrameHeight\n# Define min window size to be recognized as a face\nminW = 0.1*cam.get(3)\nminH = 0.1*cam.get(4)\n# flag = True\nwhile True:\n    ret, img =cam.read() #read the frames using the above created object",
        "detail": "Authentication.Recognition",
        "documentation": {}
    },
    {
        "label": "cam",
        "kind": 5,
        "importPath": "Authentication.Recognition",
        "description": "Authentication.Recognition",
        "peekOfCode": "cam = cv2.VideoCapture(0, cv2.CAP_DSHOW) #cv2.CAP_DSHOW to remove warning\ncam.set(3, 640) # set video FrameWidht\ncam.set(4, 480) # set video FrameHeight\n# Define min window size to be recognized as a face\nminW = 0.1*cam.get(3)\nminH = 0.1*cam.get(4)\n# flag = True\nwhile True:\n    ret, img =cam.read() #read the frames using the above created object\n    converted_image = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)  #The function converts an input image from one color space to another",
        "detail": "Authentication.Recognition",
        "documentation": {}
    },
    {
        "label": "minW",
        "kind": 5,
        "importPath": "Authentication.Recognition",
        "description": "Authentication.Recognition",
        "peekOfCode": "minW = 0.1*cam.get(3)\nminH = 0.1*cam.get(4)\n# flag = True\nwhile True:\n    ret, img =cam.read() #read the frames using the above created object\n    converted_image = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)  #The function converts an input image from one color space to another\n    faces = faceCascade.detectMultiScale( \n        converted_image,\n        scaleFactor = 1.2,\n        minNeighbors = 5,",
        "detail": "Authentication.Recognition",
        "documentation": {}
    },
    {
        "label": "minH",
        "kind": 5,
        "importPath": "Authentication.Recognition",
        "description": "Authentication.Recognition",
        "peekOfCode": "minH = 0.1*cam.get(4)\n# flag = True\nwhile True:\n    ret, img =cam.read() #read the frames using the above created object\n    converted_image = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)  #The function converts an input image from one color space to another\n    faces = faceCascade.detectMultiScale( \n        converted_image,\n        scaleFactor = 1.2,\n        minNeighbors = 5,\n        minSize = (int(minW), int(minH)),",
        "detail": "Authentication.Recognition",
        "documentation": {}
    },
    {
        "label": "SampleGenerator",
        "kind": 2,
        "importPath": "Authentication.SampleGen",
        "description": "Authentication.SampleGen",
        "peekOfCode": "def SampleGenerator(haarcascade_frontalface_default_path, SaveDataPath):\n  cam = cv2.VideoCapture(0)\n  cam.set(3, 640)\n  cam.set(4, 480)\n  detector = cv2.CascadeClassifier(haarcascade_frontalface_default_path)\n  face_id = input(\"Enter a Numeric user ID  here:  \")\n  totalCount = input(\"Enter the number of samples you want to take:  \")\n  print(\"Taking samples, look at camera ....... \")\n  count = 0\n  font = cv2.FONT_HERSHEY_SIMPLEX",
        "detail": "Authentication.SampleGen",
        "documentation": {}
    },
    {
        "label": "Images_And_Labels",
        "kind": 2,
        "importPath": "Authentication.Trainer",
        "description": "Authentication.Trainer",
        "peekOfCode": "def Images_And_Labels(path): # function to fetch the images and labels\n  imagePaths = [os.path.join(path,f) for f in os.listdir(path)]     \n  faceSamples=[]\n  ids = []\n  with alive_bar(5000) as bar:\n    for imagePath in imagePaths: # to iterate particular image path\n      gray_img = Image.open(imagePath).convert('L') # convert it to grayscale\n      img_arr = np.array(gray_img,'uint8') #creating an array\n      id = int(os.path.split(imagePath)[-1].split(\".\")[2])\n      faces = detector.detectMultiScale(img_arr)",
        "detail": "Authentication.Trainer",
        "documentation": {}
    },
    {
        "label": "path",
        "kind": 5,
        "importPath": "Authentication.Trainer",
        "description": "Authentication.Trainer",
        "peekOfCode": "path = 'Database//Samples' # Path for samples already taken\nrecognizer = cv2.face.LBPHFaceRecognizer_create() # Local Binary Patterns Histograms\ndetector = cv2.CascadeClassifier(\"Database//Haarcascades//haarcascade_frontalface_default.xml\")\ndef Images_And_Labels(path): # function to fetch the images and labels\n  imagePaths = [os.path.join(path,f) for f in os.listdir(path)]     \n  faceSamples=[]\n  ids = []\n  with alive_bar(5000) as bar:\n    for imagePath in imagePaths: # to iterate particular image path\n      gray_img = Image.open(imagePath).convert('L') # convert it to grayscale",
        "detail": "Authentication.Trainer",
        "documentation": {}
    },
    {
        "label": "recognizer",
        "kind": 5,
        "importPath": "Authentication.Trainer",
        "description": "Authentication.Trainer",
        "peekOfCode": "recognizer = cv2.face.LBPHFaceRecognizer_create() # Local Binary Patterns Histograms\ndetector = cv2.CascadeClassifier(\"Database//Haarcascades//haarcascade_frontalface_default.xml\")\ndef Images_And_Labels(path): # function to fetch the images and labels\n  imagePaths = [os.path.join(path,f) for f in os.listdir(path)]     \n  faceSamples=[]\n  ids = []\n  with alive_bar(5000) as bar:\n    for imagePath in imagePaths: # to iterate particular image path\n      gray_img = Image.open(imagePath).convert('L') # convert it to grayscale\n      img_arr = np.array(gray_img,'uint8') #creating an array",
        "detail": "Authentication.Trainer",
        "documentation": {}
    },
    {
        "label": "detector",
        "kind": 5,
        "importPath": "Authentication.Trainer",
        "description": "Authentication.Trainer",
        "peekOfCode": "detector = cv2.CascadeClassifier(\"Database//Haarcascades//haarcascade_frontalface_default.xml\")\ndef Images_And_Labels(path): # function to fetch the images and labels\n  imagePaths = [os.path.join(path,f) for f in os.listdir(path)]     \n  faceSamples=[]\n  ids = []\n  with alive_bar(5000) as bar:\n    for imagePath in imagePaths: # to iterate particular image path\n      gray_img = Image.open(imagePath).convert('L') # convert it to grayscale\n      img_arr = np.array(gray_img,'uint8') #creating an array\n      id = int(os.path.split(imagePath)[-1].split(\".\")[2])",
        "detail": "Authentication.Trainer",
        "documentation": {}
    },
    {
        "label": "faces,ids",
        "kind": 5,
        "importPath": "Authentication.Trainer",
        "description": "Authentication.Trainer",
        "peekOfCode": "faces,ids = Images_And_Labels(path)\nrecognizer.train(faces, np.array(ids))\nrecognizer.write('Database//Trained_Modal//TrainedData.yml')  # Save the trained model as trainer.yml\nprint(\"Model trained, Now we can recognize your face.\")",
        "detail": "Authentication.Trainer",
        "documentation": {}
    },
    {
        "label": "Listen",
        "kind": 2,
        "importPath": "Tests.Listen1",
        "description": "Tests.Listen1",
        "peekOfCode": "def Listen():\n  text_element_xpath = '/html/body/div[3]/section/div/div/div[2]/div/div[2]'\n  text = driver.find_element(by=By.XPATH, value=text_element_xpath).text\n  if len(text) == 0:\n    return \"\"\n  else:\n    driver.find_element(by=By.XPATH, value=clear_button_xpath).click()\n    text = text.strip()\n    print(f\"User   : {text}\")\n    return text",
        "detail": "Tests.Listen1",
        "documentation": {}
    },
    {
        "label": "url",
        "kind": 5,
        "importPath": "Tests.Listen1",
        "description": "Tests.Listen1",
        "peekOfCode": "url = \"https://dictation.io/speech\"\nwarnings.simplefilter(\"ignore\")\nstart = time.time()\ntry:\n  user_agent = 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.2 (KHTML, like Gecko) Chrome/22.0.1216.0 Safari/537.2'\n  chrome_options = Options()\n  chrome_options.add_argument(f'user-agent={user_agent}')\n  # chrome_options.add_argument(f'--headless=new')\n  chrome_options.add_experimental_option('excludeSwitches', ['enable-logging'])\n  chrome_options.add_argument('--log-level=3')",
        "detail": "Tests.Listen1",
        "documentation": {}
    },
    {
        "label": "start",
        "kind": 5,
        "importPath": "Tests.Listen1",
        "description": "Tests.Listen1",
        "peekOfCode": "start = time.time()\ntry:\n  user_agent = 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.2 (KHTML, like Gecko) Chrome/22.0.1216.0 Safari/537.2'\n  chrome_options = Options()\n  chrome_options.add_argument(f'user-agent={user_agent}')\n  # chrome_options.add_argument(f'--headless=new')\n  chrome_options.add_experimental_option('excludeSwitches', ['enable-logging'])\n  chrome_options.add_argument('--log-level=3')\n  service = Service(ChromeDriverManager().install())\n  chrome_options.add_argument(\"--use-fake-ui-for-media-stream\")",
        "detail": "Tests.Listen1",
        "documentation": {}
    },
    {
        "label": "end",
        "kind": 5,
        "importPath": "Tests.Listen1",
        "description": "Tests.Listen1",
        "peekOfCode": "end = time.time()\nprint(end - start)\ndef Listen():\n  text_element_xpath = '/html/body/div[3]/section/div/div/div[2]/div/div[2]'\n  text = driver.find_element(by=By.XPATH, value=text_element_xpath).text\n  if len(text) == 0:\n    return \"\"\n  else:\n    driver.find_element(by=By.XPATH, value=clear_button_xpath).click()\n    text = text.strip()",
        "detail": "Tests.Listen1",
        "documentation": {}
    },
    {
        "label": "Listen",
        "kind": 2,
        "importPath": "Tests.Listen2",
        "description": "Tests.Listen2",
        "peekOfCode": "def Listen():\n  text_element_xpath = '/html/body/div[4]/div/div[1]/div[2]/textarea'\n  text_element = driver.find_element(by=By.XPATH, value=text_element_xpath)\n  text = text_element.get_attribute('value')\n  if len(text) == 0:\n    pass\n  else:\n    # driver.find_element(by=By.XPATH, value=\"a\").click()\n    text = text.strip()\n    print(f\"User   : {text}\")",
        "detail": "Tests.Listen2",
        "documentation": {}
    },
    {
        "label": "url",
        "kind": 5,
        "importPath": "Tests.Listen2",
        "description": "Tests.Listen2",
        "peekOfCode": "url = \"https://speechnotes.co/dictate/\"\nwarnings.simplefilter(\"ignore\")\ntry:\n  user_agent = 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.2 (KHTML, like Gecko) Chrome/22.0.1216.0 Safari/537.2'\n  chrome_options = Options()\n  chrome_options.add_argument(f'user-agent={user_agent}')\n  chrome_options.add_argument(f'--headless=new')\n  chrome_options.add_experimental_option('excludeSwitches', ['enable-logging'])\n  chrome_options.add_argument('--log-level=3')\n  service = Service(ChromeDriverManager().install())",
        "detail": "Tests.Listen2",
        "documentation": {}
    },
    {
        "label": "Speak",
        "kind": 2,
        "importPath": "Tests.Speak1",
        "description": "Tests.Speak1",
        "peekOfCode": "def Speak(text):\n  try:\n    TextBox.clear()\n  except:\n    pass\n  TextBox.send_keys(text)\n  driver.find_element(by=By.XPATH, value=\"/html/body/app-root/app-main/app-pw-page/div/div[2]/app-pw-single-page/div[1]/div[1]/div/div[2]/app-pw-reading-bar/div/div/button[3]\").click()\n  sleep(1.5)\n  Assistant.say(text)\n  print(f\"Jarvis : {text}\")",
        "detail": "Tests.Speak1",
        "documentation": {}
    },
    {
        "label": "url",
        "kind": 5,
        "importPath": "Tests.Speak1",
        "description": "Tests.Speak1",
        "peekOfCode": "url = \"https://www.naturalreaders.com/online/\"\nwarnings.simplefilter(\"ignore\")\nAssistant = pyttsx3.init('sapi5')\nvoices = Assistant.getProperty('voices')\nAssistant.setProperty('voice', voices[0])\nAssistant.setProperty('rate', 80)\nAssistant.setProperty('volume', 0)\nuser_agent = 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.2 (KHTML, like Gecko) Chrome/22.0.1216.0 Safari/537.2'\nchrome_options = Options()\nchrome_options.add_argument(\"--start-maximized\")",
        "detail": "Tests.Speak1",
        "documentation": {}
    },
    {
        "label": "Assistant",
        "kind": 5,
        "importPath": "Tests.Speak1",
        "description": "Tests.Speak1",
        "peekOfCode": "Assistant = pyttsx3.init('sapi5')\nvoices = Assistant.getProperty('voices')\nAssistant.setProperty('voice', voices[0])\nAssistant.setProperty('rate', 80)\nAssistant.setProperty('volume', 0)\nuser_agent = 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.2 (KHTML, like Gecko) Chrome/22.0.1216.0 Safari/537.2'\nchrome_options = Options()\nchrome_options.add_argument(\"--start-maximized\")\nchrome_options.add_argument(f'user-agent={user_agent}')\nchrome_options.add_argument(f'--headless=new')",
        "detail": "Tests.Speak1",
        "documentation": {}
    },
    {
        "label": "voices",
        "kind": 5,
        "importPath": "Tests.Speak1",
        "description": "Tests.Speak1",
        "peekOfCode": "voices = Assistant.getProperty('voices')\nAssistant.setProperty('voice', voices[0])\nAssistant.setProperty('rate', 80)\nAssistant.setProperty('volume', 0)\nuser_agent = 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.2 (KHTML, like Gecko) Chrome/22.0.1216.0 Safari/537.2'\nchrome_options = Options()\nchrome_options.add_argument(\"--start-maximized\")\nchrome_options.add_argument(f'user-agent={user_agent}')\nchrome_options.add_argument(f'--headless=new')\nchrome_options.add_experimental_option('excludeSwitches', ['enable-logging'])",
        "detail": "Tests.Speak1",
        "documentation": {}
    },
    {
        "label": "user_agent",
        "kind": 5,
        "importPath": "Tests.Speak1",
        "description": "Tests.Speak1",
        "peekOfCode": "user_agent = 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.2 (KHTML, like Gecko) Chrome/22.0.1216.0 Safari/537.2'\nchrome_options = Options()\nchrome_options.add_argument(\"--start-maximized\")\nchrome_options.add_argument(f'user-agent={user_agent}')\nchrome_options.add_argument(f'--headless=new')\nchrome_options.add_experimental_option('excludeSwitches', ['enable-logging'])\nchrome_options.add_argument('--log-level=3')\nservice = Service(ChromeDriverManager().install())\nchrome_options.add_argument(\"--use-fake-ui-for-media-stream\")\nchrome_options.add_argument(\"--use-fake-device-for-media-stream\")",
        "detail": "Tests.Speak1",
        "documentation": {}
    },
    {
        "label": "chrome_options",
        "kind": 5,
        "importPath": "Tests.Speak1",
        "description": "Tests.Speak1",
        "peekOfCode": "chrome_options = Options()\nchrome_options.add_argument(\"--start-maximized\")\nchrome_options.add_argument(f'user-agent={user_agent}')\nchrome_options.add_argument(f'--headless=new')\nchrome_options.add_experimental_option('excludeSwitches', ['enable-logging'])\nchrome_options.add_argument('--log-level=3')\nservice = Service(ChromeDriverManager().install())\nchrome_options.add_argument(\"--use-fake-ui-for-media-stream\")\nchrome_options.add_argument(\"--use-fake-device-for-media-stream\")\ndriver = webdriver.Chrome(service=service, options=chrome_options)",
        "detail": "Tests.Speak1",
        "documentation": {}
    },
    {
        "label": "service",
        "kind": 5,
        "importPath": "Tests.Speak1",
        "description": "Tests.Speak1",
        "peekOfCode": "service = Service(ChromeDriverManager().install())\nchrome_options.add_argument(\"--use-fake-ui-for-media-stream\")\nchrome_options.add_argument(\"--use-fake-device-for-media-stream\")\ndriver = webdriver.Chrome(service=service, options=chrome_options)\ndriver.get(url)\ndriver.find_element(by=By.XPATH, value=\"/html/body/app-root/app-voice-selection/div/div[1]/div[2]/div/button[3]\").click()\ndriver.find_element(by=By.XPATH, value=\"/html/body/app-root/app-voice-selection/div/div[1]/div[3]/button\").click()\ndriver.find_element(by=By.XPATH, value=\"/html/body/app-root/app-voice-selection/div/div[2]/div[2]/div[1]/a\").click()\nsleep(3)\nTextBoxPath = \"/html/body/app-root/app-main/app-pw-page/div/div[2]/app-pw-single-page/div[1]/div[2]/app-pw-text-reading/div/div/div[2]/div\"",
        "detail": "Tests.Speak1",
        "documentation": {}
    },
    {
        "label": "driver",
        "kind": 5,
        "importPath": "Tests.Speak1",
        "description": "Tests.Speak1",
        "peekOfCode": "driver = webdriver.Chrome(service=service, options=chrome_options)\ndriver.get(url)\ndriver.find_element(by=By.XPATH, value=\"/html/body/app-root/app-voice-selection/div/div[1]/div[2]/div/button[3]\").click()\ndriver.find_element(by=By.XPATH, value=\"/html/body/app-root/app-voice-selection/div/div[1]/div[3]/button\").click()\ndriver.find_element(by=By.XPATH, value=\"/html/body/app-root/app-voice-selection/div/div[2]/div[2]/div[1]/a\").click()\nsleep(3)\nTextBoxPath = \"/html/body/app-root/app-main/app-pw-page/div/div[2]/app-pw-single-page/div[1]/div[2]/app-pw-text-reading/div/div/div[2]/div\"\nTextBox = driver.find_element(by=By.XPATH, value=TextBoxPath)\nTextBox.clear()\ndef Speak(text):",
        "detail": "Tests.Speak1",
        "documentation": {}
    },
    {
        "label": "TextBoxPath",
        "kind": 5,
        "importPath": "Tests.Speak1",
        "description": "Tests.Speak1",
        "peekOfCode": "TextBoxPath = \"/html/body/app-root/app-main/app-pw-page/div/div[2]/app-pw-single-page/div[1]/div[2]/app-pw-text-reading/div/div/div[2]/div\"\nTextBox = driver.find_element(by=By.XPATH, value=TextBoxPath)\nTextBox.clear()\ndef Speak(text):\n  try:\n    TextBox.clear()\n  except:\n    pass\n  TextBox.send_keys(text)\n  driver.find_element(by=By.XPATH, value=\"/html/body/app-root/app-main/app-pw-page/div/div[2]/app-pw-single-page/div[1]/div[1]/div/div[2]/app-pw-reading-bar/div/div/button[3]\").click()",
        "detail": "Tests.Speak1",
        "documentation": {}
    },
    {
        "label": "TextBox",
        "kind": 5,
        "importPath": "Tests.Speak1",
        "description": "Tests.Speak1",
        "peekOfCode": "TextBox = driver.find_element(by=By.XPATH, value=TextBoxPath)\nTextBox.clear()\ndef Speak(text):\n  try:\n    TextBox.clear()\n  except:\n    pass\n  TextBox.send_keys(text)\n  driver.find_element(by=By.XPATH, value=\"/html/body/app-root/app-main/app-pw-page/div/div[2]/app-pw-single-page/div[1]/div[1]/div/div[2]/app-pw-reading-bar/div/div/button[3]\").click()\n  sleep(1.5)",
        "detail": "Tests.Speak1",
        "documentation": {}
    },
    {
        "label": "SpeakPyttsx3",
        "kind": 2,
        "importPath": "Tests.Speak2",
        "description": "Tests.Speak2",
        "peekOfCode": "def SpeakPyttsx3(audio):\n  if audio == \"\":\n    return\n  Assistant.say(audio)\n  print(f\"Jarvis : {audio}\")\n  Assistant.runAndWait()\nif __name__ == \"__main__\":\n  SpeakPyttsx3(\"Hello, I am Jarvis.\")",
        "detail": "Tests.Speak2",
        "documentation": {}
    },
    {
        "label": "Assistant",
        "kind": 5,
        "importPath": "Tests.Speak2",
        "description": "Tests.Speak2",
        "peekOfCode": "Assistant = pyttsx3.init('sapi5')\nvoices = Assistant.getProperty('voices')\nAssistant.setProperty('voices', voices[0])\nAssistant.setProperty('rate', 180)\ndef SpeakPyttsx3(audio):\n  if audio == \"\":\n    return\n  Assistant.say(audio)\n  print(f\"Jarvis : {audio}\")\n  Assistant.runAndWait()",
        "detail": "Tests.Speak2",
        "documentation": {}
    },
    {
        "label": "voices",
        "kind": 5,
        "importPath": "Tests.Speak2",
        "description": "Tests.Speak2",
        "peekOfCode": "voices = Assistant.getProperty('voices')\nAssistant.setProperty('voices', voices[0])\nAssistant.setProperty('rate', 180)\ndef SpeakPyttsx3(audio):\n  if audio == \"\":\n    return\n  Assistant.say(audio)\n  print(f\"Jarvis : {audio}\")\n  Assistant.runAndWait()\nif __name__ == \"__main__\":",
        "detail": "Tests.Speak2",
        "documentation": {}
    },
    {
        "label": "Execution",
        "kind": 2,
        "importPath": "Jarvis",
        "description": "Jarvis",
        "peekOfCode": "def Execution():\n  while True:\n    query = Listen()\n    Speak(query)\nif __name__ == \"__main__\":\n  Execution()",
        "detail": "Jarvis",
        "documentation": {}
    },
    {
        "label": "ConvL",
        "kind": 5,
        "importPath": "Jarvis",
        "description": "Jarvis",
        "peekOfCode": "ConvL = [\n  \"\",\n  \"\"\n]\nfrom Functions.Listen import Listen\nfrom Functions.Speak import Speak\nConvT = 100\ndef Execution():\n  while True:\n    query = Listen()",
        "detail": "Jarvis",
        "documentation": {}
    },
    {
        "label": "ConvT",
        "kind": 5,
        "importPath": "Jarvis",
        "description": "Jarvis",
        "peekOfCode": "ConvT = 100\ndef Execution():\n  while True:\n    query = Listen()\n    Speak(query)\nif __name__ == \"__main__\":\n  Execution()",
        "detail": "Jarvis",
        "documentation": {}
    }
]